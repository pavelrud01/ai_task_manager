import json
import time
from openai import OpenAI
from openai.types.chat import ChatCompletion
import config

class LLMError(Exception):
    """–ö–∞—Å—Ç–æ–º–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–æ–∫ LLM."""
    pass

class LLM:
    def __init__(self):
        if not config.OPENAI_API_KEY:
            raise LLMError("OPENAI_API_KEY is not configured")
        self.client = OpenAI(api_key=config.OPENAI_API_KEY)
        self.max_retries = 3
        self.retry_delay = 2  # —Å–µ–∫—É–Ω–¥—ã
        
    def generate_json(self, system_prompt: str, user_prompt: str, org_context: str, 
                      standard_schema: dict, standard_text: str = "", reflection_notes: str = "") -> dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSON-–æ—Ç–≤–µ—Ç –æ—Ç LLM —Å —É—á–µ—Ç–æ–º —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.
        –í–∫–ª—é—á–∞–µ—Ç retry-–ª–æ–≥–∏–∫—É –∏ —É–ª—É—á—à–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫.
        """
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–º–µ—Ç–∫–∏ –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ –ø—Ä–æ–º–ø—Ç
        if reflection_notes:
            user_prompt += f"""

CRITICAL FEEDBACK ON PREVIOUS ATTEMPT:
---
{reflection_notes}
---
You MUST address this feedback in your new response.
"""

        full_system_prompt = self._build_system_prompt(
            system_prompt, org_context, standard_text, standard_schema
        )

        # Retry loop
        last_error = None
        for attempt in range(self.max_retries):
            try:
                return self._make_api_call(full_system_prompt, user_prompt, attempt)
                
            except Exception as e:
                last_error = e
                print(f"üîÑ [RETRY] Attempt {attempt + 1}/{self.max_retries} failed: {str(e)}")
                
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (attempt + 1))  # Exponential backoff
                    continue
                else:
                    break
        
        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å
        error_message = f"LLM failed after {self.max_retries} attempts. Last error: {str(last_error)}"
        return {
            "data": {"error": error_message, "fallback_used": True},
            "score": 0.0,
            "uncertainty": 1.0,
            "notes": error_message
        }
    
    def _build_system_prompt(self, base_prompt: str, org_context: str, 
                           standard_text: str, standard_schema: dict) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç."""
        return f"""
{base_prompt}

You MUST follow these instructions:
1. Think step-by-step to analyze the user request.
2. Your final output MUST be a single, valid JSON object. Do not include any text, explanations, or markdown formatting before or after the JSON.
3. Your output MUST strictly adhere to the provided JSON Schema (STANDARD section).
4. You MUST also consider the quality guidelines and checklists from the TEXTUAL STANDARD section to ensure the substance of your response is high quality.
5. Include these meta-fields in your JSON response for self-assessment:
   - "self_assessed_score": float between 0.0 and 1.0
   - "uncertainty_score": float between 0.0 and 1.0  
   - "reasoning": string with brief explanation of your approach

ORGANIZATIONAL CONTEXT (for background):
---
{org_context or "No organizational context provided."}
---

TEXTUAL STANDARD (Quality Guidelines):
---
{standard_text or "No textual standard provided."}
---

STANDARD (JSON Schema for output format):
---
{json.dumps(standard_schema, indent=2) if standard_schema else "No schema provided."}
---
"""

    def _make_api_call(self, system_prompt: str, user_prompt: str, attempt: int) -> dict:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç API –≤—ã–∑–æ–≤ –∫ OpenAI —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        try:
            completion = self.client.chat.completions.create(
                model=config.MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.5 + (attempt * 0.1),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–∞—Ö
                max_tokens=4000,
                timeout=60
            )
            
            response_text = completion.choices[0].message.content
            if not response_text:
                raise LLMError("Empty response from LLM")
                
            data = json.loads(response_text)
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∞–∑–æ–≤—ã—Ö –ø–æ–ª–µ–π
            if not isinstance(data, dict):
                raise LLMError("Response is not a valid JSON object")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞-–ø–æ–ª—è –∏ —É–¥–∞–ª—è–µ–º –∏—Ö –∏–∑ –∏—Ç–æ–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            score = data.pop("self_assessed_score", 0.8) 
            uncertainty = data.pop("uncertainty_score", 0.2)
            notes = data.pop("reasoning", "No reasoning provided by LLM.")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –º–µ—Ç–∞-–ø–æ–ª–µ–π
            score = max(0.0, min(1.0, float(score)))
            uncertainty = max(0.0, min(1.0, float(uncertainty)))

            return {
                "data": data,
                "score": score,
                "uncertainty": uncertainty,
                "notes": notes
            }

        except json.JSONDecodeError as e:
            raise LLMError(f"Invalid JSON in LLM response: {str(e)}. Response: {response_text[:200]}...")
        except Exception as e:
            if "rate limit" in str(e).lower():
                time.sleep(60)  # –ñ–¥–µ–º –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤
                raise LLMError(f"Rate limit exceeded: {str(e)}")
            else:
                raise LLMError(f"API call failed: {str(e)}")
    
    def estimate_tokens(self, text: str) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ."""
        return len(text.split()) * 1.3  # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞