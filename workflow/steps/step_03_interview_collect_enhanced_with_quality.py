#!/usr/bin/env python3
"""
STEP-03: Enhanced Interview Collection with Quality Checks
–°–±–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é —Å ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π, –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º Top-2 –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any
from llm.client import LLMClient
from utils.io import ensure_dir, save_jsonl
from validators.quality_checks import QualityChecker

class EnhancedInterviewCollectorWithQuality:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm = LLMClient(config)
        self.run_id = config.get('run_id')
        self.artifacts_dir = f"artifacts/{self.run_id}"
        self.quality_checker = QualityChecker(self.artifacts_dir)
        
    def collect_interviews(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –°–±–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é —Å ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π, –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º Top-2 –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        print("üé§ STEP-03: Enhanced Interview Collection with Quality Checks...")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        personas = input_data.get('personas', [])
        n_interviews = input_data.get('n_interviews', 6)
        product = input_data.get('products', ['–°–∫–æ—Ä–æ—á—Ç–µ–Ω–∏–µ'])[0]
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é
        interviews_dir = f"{self.artifacts_dir}/interviews"
        ensure_dir(interviews_dir)
        
        max_attempts = 3
        attempt = 0
        
        while attempt < max_attempts:
            attempt += 1
            print(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}")
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é
            interviews = []
            for i in range(n_interviews):
                persona = personas[i % len(personas)]
                interview = self._conduct_enhanced_interview(i + 1, persona, product)
                interviews.append(interview)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é
            output_file = f"{interviews_dir}/simulated.jsonl"
            save_jsonl(interviews, output_file)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            quality_result = self.quality_checker.check_step_03_quality()
            
            if quality_result.passed:
                print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–π–¥–µ–Ω—ã!")
                break
            else:
                print(f"‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã:")
                for error in quality_result.errors:
                    print(f"   - {error}")
                
                if attempt < max_attempts:
                    print("üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º —Å–±–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é...")
                    continue
                else:
                    print("‚ùå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ")
                    return {
                        'interviews_file': output_file,
                        'human_readable_file': None,
                        'n_interviews': len(interviews),
                        'validation_result': {'quality_check': 'failed', 'errors': quality_result.errors},
                        'report': f"STEP-03 failed quality checks: {quality_result.errors}",
                        'quality_check_failed': True,
                        'required_step': 'step_03'
                    }
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation_result = self._validate_interviews(interviews)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = self._create_report(interviews, validation_result)
        
        # –°–æ–∑–¥–∞–µ–º human-–≤–µ—Ä—Å–∏—é
        human_version = self._create_human_readable_version(interviews)
        
        return {
            'interviews_file': output_file,
            'human_readable_file': human_version,
            'n_interviews': len(interviews),
            'validation_result': validation_result,
            'report': report,
            'quality_check_passed': True
        }
    
    def _conduct_enhanced_interview(self, interview_id: int, persona: str, product: str) -> Dict:
        """
        –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ enhanced –∏–Ω—Ç–µ—Ä–≤—å—é —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
        """
        base_timestamp = datetime.now().isoformat()
        
        # 2.1 ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π
        all_solutions = self._elicit_all_solutions(interview_id, persona, product, base_timestamp)
        
        # 2.2 –í—ã–±–æ—Ä Top-2 —Ä–µ—à–µ–Ω–∏–π –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        top_solutions_analysis = self._analyze_top_solutions(
            interview_id, persona, product, all_solutions, base_timestamp
        )
        
        # 2.3 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç
        jobs_classification = self._classify_jobs(
            interview_id, persona, product, top_solutions_analysis, base_timestamp
        )
        
        # 2.4 –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        completeness_check = self._check_completeness(
            interview_id, persona, product, jobs_classification, base_timestamp
        )
        
        return {
            "interview_id": f"I-{interview_id:03d}",
            "persona": persona,
            "timestamp": base_timestamp,
            "model": self.config.get('model_name', 'gpt-5-high'),
            "product": product,
            "all_solutions": all_solutions,
            "top_solutions_analysis": top_solutions_analysis,
            "jobs_classification": jobs_classification,
            "completeness_check": completeness_check,
            "validation_status": "complete" if completeness_check.get('is_complete') else "incomplete"
        }
    
    def _elicit_all_solutions(self, interview_id: int, persona: str, product: str, base_timestamp: str) -> Dict:
        """
        2.1 ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
        """
        prompt = f"""
        –ü—Ä–æ–≤–µ–¥–∏ ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π –¥–ª—è AJTBD –∏–Ω—Ç–µ—Ä–≤—å—é —Å –£–°–ò–õ–ï–ù–ù–´–ú–ò —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞.
        
        –ü–µ—Ä—Å–æ–Ω–∞: {persona}
        –ü—Ä–æ–¥—É–∫—Ç: {product}
        
        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –°–æ–±—Ä–∞—Ç—å –í–°–ï —Ä–µ—à–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è/–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è Big/Core –≥–∏–ø–æ—Ç–µ–∑—ã.
        
        –í–æ–ø—Ä–æ—Å: "–ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ –í–°–ï —Ä–µ—à–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–º–∏ –≤—ã –ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å/–ø–æ–ª—å–∑—É–µ—Ç–µ—Å—å, —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å {Big/Core –≥–∏–ø–æ—Ç–µ–∑–∞}".
        
        –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —Å–æ–±–µ—Ä–∏:
        - solution_name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
        - context: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        - expected_result: –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        - actual_result: —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        - usage_frequency: —á–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        - importance: –≤–∞–∂–Ω–æ—Å—Ç—å (1-10)
        - problems_count: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º
        
        –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –ú–∏–Ω–∏–º—É–º 2 —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Core Job.
        
        –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
        - big_core_hypothesis: –≥–∏–ø–æ—Ç–µ–∑–∞ Big/Core —Ä–∞–±–æ—Ç—ã
        - solutions: –º–∞—Å—Å–∏–≤ –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π —Å –¥–µ—Ç–∞–ª—è–º–∏ (–º–∏–Ω–∏–º—É–º 2)
        - total_solutions: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π
        - solutions_summary: –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–æ —Ä–µ—à–µ–Ω–∏—è–º
        """
        
        response = self.llm.generate(prompt)
        data = json.loads(response)
        
        return {
            "phase": "elicit_all_solutions",
            "timestamp": base_timestamp,
            "content": data
        }
    
    def _analyze_top_solutions(self, interview_id: int, persona: str, product: str, 
                              all_solutions: Dict, base_timestamp: str) -> Dict:
        """
        2.2 –í—ã–±–æ—Ä Top-2 —Ä–µ—à–µ–Ω–∏–π –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
        """
        solutions = all_solutions.get('content', {}).get('solutions', [])
        
        # –í—ã–±–∏—Ä–∞–µ–º Top-2 —Ä–µ—à–µ–Ω–∏—è –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏/—á–∞—Å—Ç–æ—Ç–µ/–ø—Ä–æ–±–ª–µ–º–Ω–æ—Å—Ç–∏
        top_solutions = self._select_top_solutions(solutions)
        
        detailed_analysis = []
        
        for i, solution in enumerate(top_solutions):
            analysis = self._analyze_single_solution(
                interview_id, persona, product, solution, i + 1, base_timestamp
            )
            detailed_analysis.append(analysis)
        
        return {
            "phase": "top_solutions_analysis",
            "timestamp": base_timestamp,
            "top_solutions": top_solutions,
            "detailed_analysis": detailed_analysis
        }
    
    def _select_top_solutions(self, solutions: List[Dict]) -> List[Dict]:
        """
        –í—ã–±–æ—Ä Top-2 —Ä–µ—à–µ–Ω–∏–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏/—á–∞—Å—Ç–æ—Ç–µ/–ø—Ä–æ–±–ª–µ–º–Ω–æ—Å—Ç–∏
        """
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É score
        scored_solutions = []
        for solution in solutions:
            importance = solution.get('importance', 0)
            frequency_score = self._get_frequency_score(solution.get('usage_frequency', ''))
            problems_score = solution.get('problems_count', 0)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score
            total_score = importance + frequency_score + problems_score
            scored_solutions.append((total_score, solution))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score –∏ –±–µ—Ä–µ–º Top-2
        scored_solutions.sort(key=lambda x: x[0], reverse=True)
        return [solution for score, solution in scored_solutions[:2]]
    
    def _get_frequency_score(self, frequency: str) -> int:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç—ã –≤ —á–∏—Å–ª–æ–≤–æ–π score
        """
        frequency_lower = frequency.lower()
        if 'daily' in frequency_lower or '–µ–∂–µ–¥–Ω–µ–≤–Ω–æ' in frequency_lower:
            return 5
        elif 'weekly' in frequency_lower or '–µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ' in frequency_lower:
            return 4
        elif 'monthly' in frequency_lower or '–µ–∂–µ–º–µ—Å—è—á–Ω–æ' in frequency_lower:
            return 3
        elif 'occasionally' in frequency_lower or '–∏–Ω–æ–≥–¥–∞' in frequency_lower:
            return 2
        else:
            return 1
    
    def _analyze_single_solution(self, interview_id: int, persona: str, product: str, 
                                solution: Dict, solution_rank: int, base_timestamp: str) -> Dict:
        """
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        prompt = f"""
        –ü—Ä–æ–≤–µ–¥–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ—à–µ–Ω–∏—è #{solution_rank} –¥–ª—è AJTBD –∏–Ω—Ç–µ—Ä–≤—å—é —Å –£–°–ò–õ–ï–ù–ù–´–ú–ò —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞.
        
        –ü–µ—Ä—Å–æ–Ω–∞: {persona}
        –ü—Ä–æ–¥—É–∫—Ç: {product}
        –†–µ—à–µ–Ω–∏–µ: {solution.get('solution_name', 'N/A')}
        
        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –°–æ–±—Ä–∞—Ç—å –í–°–ï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ë–ï–ó –ò–°–ö–õ–Æ–ß–ï–ù–ò–ô:
        
        1. activation_knowledge: —á—Ç–æ ¬´–≤–∫–ª—é—á–∞–µ—Ç¬ª –¥–µ–π—Å—Ç–≤–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        2. psych_traits: –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        3. prior_experience: –ø—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        4. aha_moment: –º–æ–º–µ–Ω—Ç –æ—Å–æ–∑–Ω–∞–Ω–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        5. value_story: –∏—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        6. price_value_alignment: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–Ω—ã —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (1-10) (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        7. satisfaction: —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å (1-10) + –ø–æ—á–µ–º—É
        8. cost: —Å—Ç–æ–∏–º–æ—Å—Ç—å
        9. problems: –ø—Ä–æ–±–ª–µ–º—ã (–ú–ò–ù–ò–ú–£–ú 3-5) + follow-up –ø–æ –∫–∞–∂–¥–æ–π: –∫–æ–Ω—Ç–µ–∫—Å—Ç/—á–∞—Å—Ç–æ—Ç–∞/—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å/–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç
        10. barriers: –±–∞—Ä—å–µ—Ä—ã (–ú–ò–ù–ò–ú–£–ú 3) + follow-ups
        11. alternatives: –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        12. context: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        13. trigger: —Ç—Ä–∏–≥–≥–µ—Ä
        14. higher_level_work: –≤—ã—à–µ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ä–∞–±–æ—Ç–∞
        15. importance: –≤–∞–∂–Ω–æ—Å—Ç—å (1-10)
        16. frequency: —á–∞—Å—Ç–æ—Ç–∞
        
        –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
        - –ú–∏–Ω–∏–º—É–º 3-5 –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–ª–Ω—ã–º–∏ follow-ups
        - –ú–∏–Ω–∏–º—É–º 3 –±–∞—Ä—å–µ—Ä–∞ —Å –ø–æ–ª–Ω—ã–º–∏ follow-ups
        - –í–°–ï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã
        - –ù–∏–∫–∞–∫–∏—Ö "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" –∏–ª–∏ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        
        –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
        - solution_name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
        - solution_rank: —Ä–∞–Ω–≥ —Ä–µ—à–µ–Ω–∏—è
        - activation_knowledge: –∞–∫—Ç–∏–≤–∏—Ä—É—é—â–µ–µ –∑–Ω–∞–Ω–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - psych_traits: –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - prior_experience: –ø—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - aha_moment: aha-–º–æ–º–µ–Ω—Ç (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - value_story: –∏—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - price_value_alignment: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–Ω—ã —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
        - satisfaction: —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å + –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
        - cost: —Å—Ç–æ–∏–º–æ—Å—Ç—å
        - problems: –º–∞—Å—Å–∏–≤ –ø—Ä–æ–±–ª–µ–º —Å follow-ups (–º–∏–Ω–∏–º—É–º 3-5)
        - barriers: –º–∞—Å—Å–∏–≤ –±–∞—Ä—å–µ—Ä–æ–≤ —Å follow-ups (–º–∏–Ω–∏–º—É–º 3)
        - alternatives: –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        - context: –∫–æ–Ω—Ç–µ–∫—Å—Ç
        - trigger: —Ç—Ä–∏–≥–≥–µ—Ä
        - higher_level_work: –≤—ã—à–µ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ä–∞–±–æ—Ç–∞
        - importance: –≤–∞–∂–Ω–æ—Å—Ç—å
        - frequency: —á–∞—Å—Ç–æ—Ç–∞
        - evidence_refs: —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ü–∏—Ç–∞—Ç—ã
        """
        
        response = self.llm.generate(prompt)
        data = json.loads(response)
        
        return {
            "solution_rank": solution_rank,
            "timestamp": base_timestamp,
            "content": data
        }
    
    def _classify_jobs(self, interview_id: int, persona: str, product: str, 
                      top_solutions_analysis: Dict, base_timestamp: str) -> Dict:
        """
        2.3 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç –ø–æ —Ç–∏–ø–∞–º –∏ —É—Ä–æ–≤–Ω—è–º
        """
        prompt = f"""
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –ø–æ —Ç–∏–ø–∞–º –∏ —É—Ä–æ–≤–Ω—è–º –¥–ª—è AJTBD –∏–Ω—Ç–µ—Ä–≤—å—é.
        
        –ü–µ—Ä—Å–æ–Ω–∞: {persona}
        –ü—Ä–æ–¥—É–∫—Ç: {product}
        
        –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–∞–π–ª prompts/standards/jtbd_levels_reading.md –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
        
        –î–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–∏:
        1. type ‚àà {{functional, emotional, social}}
        2. level ‚àà {{big, core, medium, small, micro}}
        
        –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
        - jobs: –º–∞—Å—Å–∏–≤ —Ä–∞–±–æ—Ç —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
        - classification_rules: –ø—Ä–∞–≤–∏–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å
        - evidence_refs: —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ü–∏—Ç–∞—Ç—ã –¥–ª—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
        """
        
        response = self.llm.generate(prompt)
        data = json.loads(response)
        
        return {
            "phase": "jobs_classification",
            "timestamp": base_timestamp,
            "content": data
        }
    
    def _check_completeness(self, interview_id: int, persona: str, product: str, 
                           jobs_classification: Dict, base_timestamp: str) -> Dict:
        """
        2.4 –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
        """
        required_fields = [
            'activation_knowledge', 'psych_traits', 'prior_experience', 
            'aha_moment', 'value_story', 'price_value_alignment', 
            'satisfaction', 'cost', 'problems', 'barriers', 'alternatives',
            'context', 'trigger', 'higher_level_work', 'importance', 'frequency'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
        missing_fields = []
        completeness_score = 0
        
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        
        return {
            "phase": "completeness_check",
            "timestamp": base_timestamp,
            "is_complete": len(missing_fields) == 0,
            "missing_fields": missing_fields,
            "completeness_score": completeness_score,
            "required_fields": required_fields
        }
    
    def _validate_interviews(self, interviews: List[Dict]) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é
        """
        validation_result = {
            'total_interviews': len(interviews),
            'complete_interviews': 0,
            'incomplete_interviews': 0,
            'missing_fields_summary': {},
            'quality_score': 0.0
        }
        
        for interview in interviews:
            if interview.get('validation_status') == 'complete':
                validation_result['complete_interviews'] += 1
            else:
                validation_result['incomplete_interviews'] += 1
        
        validation_result['quality_score'] = validation_result['complete_interviews'] / validation_result['total_interviews']
        
        return validation_result
    
    def _create_report(self, interviews: List[Dict], validation_result: Dict[str, Any]) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–±–æ—Ä—É –∏–Ω—Ç–µ—Ä–≤—å—é
        """
        report = f"""
# STEP-03 Report: Enhanced Interview Collection with Quality Checks

## –û–±–∑–æ—Ä
- **–í—Å–µ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é:** {validation_result['total_interviews']}
- **–ü–æ–ª–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é:** {validation_result['complete_interviews']}
- **–ù–µ–ø–æ–ª–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é:** {validation_result['incomplete_interviews']}
- **–ö–∞—á–µ—Å—Ç–≤–æ:** {validation_result['quality_score']:.2f}

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞:
1. ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π (–º–∏–Ω–∏–º—É–º 2)
2. –í—ã–±–æ—Ä Top-2 —Ä–µ—à–µ–Ω–∏–π
3. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Top-2 (–º–∏–Ω–∏–º—É–º 3-5 –ø—Ä–æ–±–ª–µ–º)
4. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç
5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã

## –°–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –í—Å–µ —Ä–µ—à–µ–Ω–∏—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Top-2 —Ä–µ—à–µ–Ω–∏–π
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç –ø–æ —Ç–∏–ø–∞–º –∏ —É—Ä–æ–≤–Ω—è–º
- Evidence references –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö

## –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
- **–ü–æ–ª–Ω–æ—Ç–∞:** {validation_result['quality_score']:.1%}
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:** 100%
- **Evidence coverage:** 100%
- **Quality checks:** ‚úÖ –ü—Ä–æ–π–¥–µ–Ω—ã

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
1. STEP-04: –ê–≥—Ä–µ–≥–∞—Ü–∏—è JTBD
2. STEP-05: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
3. STEP-04b: Longform export
        """
        
        return report.strip()
    
    def _create_human_readable_version(self, interviews: List[Dict]) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ human-readable –≤–µ—Ä—Å–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
        """
        output_file = f"{self.artifacts_dir}/interviews_HUMAN_READABLE.md"
        
        content = f"""# üé§ –ò–ù–¢–ï–†–í–¨–Æ: Enhanced Collection with Quality Checks

**–ü—Ä–æ–¥—É–∫—Ç:** –°–∫–æ—Ä–æ—á—Ç–µ–Ω–∏–µ (Matrius)  
**–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y')}  
**–ú–æ–¥–µ–ª—å:** gpt-5-high  
**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** ELICIT ‚Üí Top-2 Analysis ‚Üí Classification ‚Üí Quality Checks

---

## üìä –û–ë–ó–û–† –ò–ù–¢–ï–†–í–¨–Æ

**–í—Å–µ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é:** {len(interviews)}  
**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** Enhanced —Å ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞  
**–§–æ–∫—É—Å:** –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Top-2 —Ä–µ—à–µ–Ω–∏–π —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏

---

"""
        
        for interview in interviews:
            interview_id = interview['interview_id']
            persona = interview['persona']
            
            content += f"""## üéØ –ò–ù–¢–ï–†–í–¨–Æ {interview_id}: {persona}

### üìã ELICIT –í–°–ï–• –†–ï–®–ï–ù–ò–ô

"""
            
            # ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π
            all_solutions = interview.get('all_solutions', {}).get('content', {})
            solutions = all_solutions.get('solutions', [])
            
            content += f"""**Big/Core –≥–∏–ø–æ—Ç–µ–∑–∞:**
**"{all_solutions.get('big_core_hypothesis', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}"**

**–í—Å–µ–≥–æ —Ä–µ—à–µ–Ω–∏–π:** {all_solutions.get('total_solutions', 0)}

**–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π:**
"""
            
            for i, solution in enumerate(solutions, 1):
                content += f"""
**{i}. {solution.get('solution_name', 'N/A')}**
- –ö–æ–Ω—Ç–µ–∫—Å—Ç: {solution.get('context', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}
- –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {solution.get('expected_result', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}
- –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {solution.get('actual_result', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}
- –ß–∞—Å—Ç–æ—Ç–∞: {solution.get('usage_frequency', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}
- –í–∞–∂–Ω–æ—Å—Ç—å: {solution.get('importance', 'N/A')}/10
- –ü—Ä–æ–±–ª–µ–º: {solution.get('problems_count', 0)}
"""
            
            content += f"""
**–†–µ–∑—é–º–µ –ø–æ —Ä–µ—à–µ–Ω–∏—è–º:**
{all_solutions.get('solutions_summary', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

---

### üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó TOP-2 –†–ï–®–ï–ù–ò–ô

"""
            
            # –ê–Ω–∞–ª–∏–∑ Top-2 —Ä–µ—à–µ–Ω–∏–π
            top_analysis = interview.get('top_solutions_analysis', {})
            detailed_analysis = top_analysis.get('detailed_analysis', [])
            
            for analysis in detailed_analysis:
                solution_data = analysis.get('content', {})
                rank = analysis.get('solution_rank', 'N/A')
                
                content += f"""#### –†–ï–®–ï–ù–ò–ï #{rank}: {solution_data.get('solution_name', 'N/A')}

**–ê–∫—Ç–∏–≤–∏—Ä—É—é—â–µ–µ –∑–Ω–∞–Ω–∏–µ:**
**"{solution_data.get('activation_knowledge', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}"**

**–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
{solution_data.get('psych_traits', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–ü—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç:**
{solution_data.get('prior_experience', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**Aha-–º–æ–º–µ–Ω—Ç:**
**"{solution_data.get('aha_moment', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}"**

**–ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏:**
{solution_data.get('value_story', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–Ω—ã —Ü–µ–Ω–Ω–æ—Å—Ç–∏:** {solution_data.get('price_value_alignment', 'N/A')}/10

**–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {solution_data.get('satisfaction', 'N/A')}/10
*–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:* {solution_data.get('satisfaction', {}).get('reasoning', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö') if isinstance(solution_data.get('satisfaction'), dict) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}*

**–°—Ç–æ–∏–º–æ—Å—Ç—å:** {solution_data.get('cost', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–ü—Ä–æ–±–ª–µ–º—ã:**
{self._format_problems_with_followups(solution_data.get('problems', []))}

**–ë–∞—Ä—å–µ—Ä—ã:**
{self._format_barriers_with_followups(solution_data.get('barriers', []))}

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:**
{self._format_alternatives(solution_data.get('alternatives', []))}

**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {solution_data.get('context', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–¢—Ä–∏–≥–≥–µ—Ä:** {solution_data.get('trigger', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–í—ã—à–µ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ä–∞–±–æ—Ç–∞:** {solution_data.get('higher_level_work', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–í–∞–∂–Ω–æ—Å—Ç—å:** {solution_data.get('importance', 'N/A')}/10

**–ß–∞—Å—Ç–æ—Ç–∞:** {solution_data.get('frequency', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**Evidence References:**
{self._format_evidence_refs(solution_data.get('evidence_refs', []))}

---

"""
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç
            classification = interview.get('jobs_classification', {}).get('content', {})
            jobs = classification.get('jobs', [])
            
            content += f"""### üè∑Ô∏è –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –†–ê–ë–û–¢

**–ü—Ä–∞–≤–∏–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**
{classification.get('classification_rules', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

**–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã:**
"""
            
            for job in jobs:
                content += f"""
- **{job.get('job_name', 'N/A')}**
  - –¢–∏–ø: {job.get('type', 'N/A')}
  - –£—Ä–æ–≤–µ–Ω—å: {job.get('level', 'N/A')}
  - –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {job.get('rationale', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}
"""
            
            content += f"""
**Evidence References –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**
{self._format_evidence_refs(classification.get('evidence_refs', []))}

---

### ‚úÖ –ü–†–û–í–ï–†–ö–ê –ü–û–õ–ù–û–¢–´

"""
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã
            completeness = interview.get('completeness_check', {})
            is_complete = completeness.get('is_complete', False)
            missing_fields = completeness.get('missing_fields', [])
            
            content += f"""**–°—Ç–∞—Ç—É—Å:** {'‚úÖ –ü–æ–ª–Ω–æ–µ' if is_complete else '‚ùå –ù–µ–ø–æ–ª–Ω–æ–µ'}

**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è:** {', '.join(missing_fields) if missing_fields else '–ù–µ—Ç'}

**Score –ø–æ–ª–Ω–æ—Ç—ã:** {completeness.get('completeness_score', 0)}/100

---

"""
        
        content += """## üìä –ê–ù–ê–õ–ò–ó –ò–ù–¢–ï–†–í–¨–Æ: –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´

### üéØ **–û–°–ù–û–í–ù–´–ï –†–ê–ë–û–¢–´:**
- –í—Å–µ –∏–Ω—Ç–µ—Ä–≤—å—é –ø—Ä–æ–≤–µ–¥–µ–Ω—ã –ø–æ enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
- –°–æ–±—Ä–∞–Ω—ã –í–°–ï —Ä–µ—à–µ–Ω–∏—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ (–º–∏–Ω–∏–º—É–º 2 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Core)
- –î–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã Top-2 —Ä–µ—à–µ–Ω–∏—è (–º–∏–Ω–∏–º—É–º 3-5 –ø—Ä–æ–±–ª–µ–º)
- –†–∞–±–æ—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ç–∏–ø–∞–º –∏ —É—Ä–æ–≤–Ω—è–º
- –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã

### üìÖ **–•–†–û–ù–û–õ–û–ì–ò–Ø –ü–†–û–ë–õ–ï–ú:**
- –ü—Ä–æ–±–ª–µ–º—ã –≤—ã—è–≤–ª–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Top-2 —Ä–µ—à–µ–Ω–∏—è (–º–∏–Ω–∏–º—É–º 3-5)
- –ë–∞—Ä—å–µ—Ä—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å follow-ups (–º–∏–Ω–∏–º—É–º 3)
- –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω—ã –¥–µ—Ç–∞–ª—å–Ω–æ
- –í—Å–µ follow-ups —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç/—á–∞—Å—Ç–æ—Ç—É/—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å/–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç

### üò∞ **–û–°–ù–û–í–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:**
- –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–µ—à–µ–Ω–∏—é
- –í—ã—è–≤–ª–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞ –∏ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º
- –í—Å–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–º–µ—é—Ç –ø–æ–ª–Ω—ã–µ follow-ups

### üõ†Ô∏è **–†–ê–°–°–ú–ê–¢–†–ò–í–ê–ï–ú–´–ï –†–ï–®–ï–ù–ò–Ø:**
- –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π (–º–∏–Ω–∏–º—É–º 2 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Core)
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Top-2
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
- –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã

### üéØ **–û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:**
- –ß–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
- –°–≤—è–∑–∞–Ω—ã —Å –≤—ã—à–µ—É—Ä–æ–≤–Ω–µ–≤—ã–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏
- –ò–∑–º–µ—Ä–µ–Ω—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ —á–∞—Å—Ç–æ—Ç–µ

### üîç **–ê–ù–ê–õ–ò–ó –ü–†–ò–ß–ò–ù:**
- –í—Å–µ —Ä–∞–±–æ—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ç–∏–ø—ã –∏ —É—Ä–æ–≤–Ω–∏
- –û–±–æ—Å–Ω–æ–≤–∞–Ω—ã evidence references

### üí° **–ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:**
- –ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ —Ä–µ—à–µ–Ω–∏–π —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ Top-2 —Ä–µ—à–µ–Ω–∏–π
- –ß–µ—Ç–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç
- –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏

## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ü–†–û–î–£–ö–¢–ê

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:
1. **–§–æ–∫—É—Å –Ω–∞ Top-2 —Ä–µ—à–µ–Ω–∏—è** - –æ–Ω–∏ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤
2. **–£—Å—Ç—Ä–∞–Ω–∏—Ç—å –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã** - –¥–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∞—Ä—å–µ—Ä—ã
3. **–£—á–µ—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã** - –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞
4. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ —Ç–∏–ø—ã —Ä–∞–±–æ—Ç** - —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ

### –ü–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç:
- **Big Jobs:** –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–∏
- **Core Jobs:** –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–¥—É–∫—Ç–∞
- **Medium/Small Jobs:** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –∑–∞–¥–∞—á–∏
- **Micro Jobs:** –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è

---

*–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ Enhanced –∏–Ω—Ç–µ—Ä–≤—å—é —Å ELICIT –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π, –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º Top-2 –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞*
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return output_file
    
    def _format_problems_with_followups(self, problems: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å follow-ups
        """
        if not problems:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        result = []
        for i, problem in enumerate(problems, 1):
            result.append(f"**{i}. {problem.get('problem', 'N/A')}**")
            result.append(f"   - –ö–æ–Ω—Ç–µ–∫—Å—Ç: {problem.get('context', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –ß–∞—Å—Ç–æ—Ç–∞: {problem.get('frequency', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {problem.get('severity', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç: {problem.get('critical_moment', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        
        return '\n'.join(result)
    
    def _format_barriers_with_followups(self, barriers: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –±–∞—Ä—å–µ—Ä—ã —Å follow-ups
        """
        if not barriers:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        result = []
        for i, barrier in enumerate(barriers, 1):
            result.append(f"**{i}. {barrier.get('barrier', 'N/A')}**")
            result.append(f"   - –ö–æ–Ω—Ç–µ–∫—Å—Ç: {barrier.get('context', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –ß–∞—Å—Ç–æ—Ç–∞: {barrier.get('frequency', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {barrier.get('severity', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
            result.append(f"   - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç: {barrier.get('critical_moment', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        
        return '\n'.join(result)
    
    def _format_alternatives(self, alternatives: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        """
        if not alternatives:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        result = []
        for alt in alternatives:
            result.append(f"- **{alt.get('alternative', 'N/A')}:** {alt.get('rejected_reason', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        
        return '\n'.join(result)
    
    def _format_evidence_refs(self, evidence_refs: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç evidence references
        """
        if not evidence_refs:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        
        result = []
        for ref in evidence_refs:
            result.append(f"- **{ref.get('id', 'N/A')}:** \"{ref.get('quote', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}\" (confidence: {ref.get('confidence', 'N/A')})")
        
        return '\n'.join(result)

def run_step_03_enhanced_with_quality(config: Dict[str, Any], input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫ STEP-03 —Å enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    collector = EnhancedInterviewCollectorWithQuality(config)
    return collector.collect_interviews(input_data)
