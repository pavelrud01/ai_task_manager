#!/usr/bin/env python3
"""
STEP-04b: Enhanced Longform Export
Longform export —Å human-readable –≤—ã—Ö–æ–¥–∞–º–∏ –ø–æ user_template
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any
from llm.client import LLMClient
from utils.io import ensure_dir

class EnhancedLongformProcessor:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm = LLMClient(config)
        self.run_id = config.get('run_id')
        self.artifacts_dir = f"artifacts/{self.run_id}"
        
    def process_longform(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ longform export —Å enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        """
        print("üìù STEP-04b: Enhanced Longform Export...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments_file = f"{self.artifacts_dir}/step_05_segments.json"
        segments_data = self._load_segments_data(segments_file)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º JTBD –¥–∞–Ω–Ω—ã–µ
        jtbd_file = f"{self.artifacts_dir}/step_04_jtbd.json"
        jtbd_data = self._load_jtbd_data(jtbd_file)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é
        interviews_file = f"{self.artifacts_dir}/interviews/simulated.jsonl"
        interviews = self._load_interviews(interviews_file)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è longform
        longform_dir = f"{self.artifacts_dir}/exports/jobs_longform"
        ensure_dir(longform_dir)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º longform –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        longform_files = []
        segments = segments_data.get('segments', [])
        
        for segment in segments:
            longform_file = self._generate_segment_longform(
                segment, jtbd_data, interviews, longform_dir
            )
            longform_files.append(longform_file)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = self._create_report(longform_files, segments)
        
        return {
            'longform_files': longform_files,
            'longform_dir': longform_dir,
            'report': report
        }
    
    def _load_segments_data(self, segments_file: str) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        if os.path.exists(segments_file):
            with open(segments_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _load_jtbd_data(self, jtbd_file: str) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ JTBD –¥–∞–Ω–Ω—ã—Ö
        """
        if os.path.exists(jtbd_file):
            with open(jtbd_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _load_interviews(self, interviews_file: str) -> List[Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é –∏–∑ —Ñ–∞–π–ª–∞
        """
        interviews = []
        if os.path.exists(interviews_file):
            with open(interviews_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        interviews.append(json.loads(line))
        return interviews
    
    def _generate_segment_longform(self, segment: Dict[str, Any], jtbd_data: Dict[str, Any], 
                                  interviews: List[Dict], longform_dir: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è longform –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ user_template
        """
        segment_id = segment.get('segment_id', 'S-001')
        output_file = f"{longform_dir}/{segment_id}.md"
        
        prompt = f"""
        –°–æ–∑–¥–∞–π longform –æ—Ç—á–µ—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É user_template.md.
        
        –°–µ–≥–º–µ–Ω—Ç: {segment.get('segment_name', 'N/A')}
        ID: {segment_id}
        
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ user_template.md:
        1. [–ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã (=—Ö–æ—á—É)] ‚Äî 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        2. [–∫–æ–≥–¥–∞] ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç/—Å–∏—Ç—É–∞—Ü–∏—è (‚â•2 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        3. [–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏] ‚Äî –º–æ—Ç–∏–≤–∞—Ü–∏–∏/—Å—Ç—Ä–∞—Ö–∏/—É—Å—Ç–∞–Ω–æ–≤–∫–∏ (‚â•2)
        4. [–ø—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç] ‚Äî —É—Ä–æ–≤–µ–Ω—å/–æ—à–∏–±–∫–∏/—á—Ç–æ –ø—Ä–æ–±–æ–≤–∞–ª–∏
        5. [–∞–∫—Ç–∏–≤–∏—Ä—É—é—â–µ–µ –∑–Ω–∞–Ω–∏–µ] ‚Äî —á—Ç–æ ¬´–≤–∫–ª—é—á–∞–µ—Ç¬ª –¥–µ–π—Å—Ç–≤–∏–µ
        6. [–•–æ—á—É] ‚Äî —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–º–µ—Ç—Ä–∏–∫–∞/–∫—Ä–∏—Ç–µ—Ä–∏–∏)
        7. [—á—Ç–æ–±—ã] ‚Äî —Ä–∞–±–æ—Ç–∞ —É—Ä–æ–≤–Ω–µ–º –≤—ã—à–µ (Big/—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ü–µ–ª—å)
        8. [–≤–∞–∂–Ω–æ—Å—Ç—å] ‚Äî 1‚Äì10
        9. [—á–∞—Å—Ç–æ—Ç–∞] ‚Äî daily/weekly/monthly/–ø–æ —Å–æ–±—ã—Ç–∏—é
        10. [—Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∫–ª–∏–µ–Ω—Ç "–Ω–∞–Ω—è–ª"] —Å –¥–µ—Ç–∞–ª—è–º–∏:
            - [—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å] ‚Äî 1‚Äì10 + –ø–æ—á–µ–º—É
            - [—Ü–µ–Ω–Ω–æ—Å—Ç—å] ‚Äî —á—Ç–æ –∏–º–µ–Ω–Ω–æ –¥–∞—ë—Ç —Ü–µ–Ω–Ω–æ—Å—Ç—å (—Å–ø–∏—Å–∫–æ–º)
            - [Aha-moment] ‚Äî –∫–æ–≥–¥–∞ ¬´—Å—Ç–∞–ª–æ —Ä–∞–±–æ—Ç–∞—Ç—å¬ª
            - [—Å—Ç–æ–∏–º–æ—Å—Ç—å] ‚Äî —Ä—É–±/–º–µ—Å –∏–ª–∏ —Ä–∞–∑–æ–≤–∞—è
            - [—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–Ω—ã —Ü–µ–Ω–Ω–æ—Å—Ç–∏] ‚Äî 1‚Äì10 + –ø–æ—á–µ–º—É
            - [–ø—Ä–æ–±–ª–µ–º—ã] ‚Äî ‚â•3, –∫–∞–∂–¥—É—é —Ä–∞—Å–∫—Ä—ã—Ç—å
            - [–±–∞—Ä—å–µ—Ä—ã] ‚Äî ‚â•3, –∫–∞–∂–¥—É—é —Ä–∞—Å–∫—Ä—ã—Ç—å
            - [–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã] ‚Äî —Ä–µ–∞–ª—å–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã + –ø–æ—á–µ–º—É –Ω–µ –≤—ã–±—Ä–∞–ª–∏
        11. [–Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —Ä–∞–±–æ—Ç—ã + —Ä–µ–∑—É–ª—å—Ç–∞—Ç] ‚Äî —Å–ø–∏—Å–æ–∫ small/micro jobs
        12. [—Ç–µ–≥–∏/–ª–µ–∫—Å–∏–∫–∞] ‚Äî —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é
        13. [evidence_refs] ‚Äî —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é/—Ü–∏—Ç–∞—Ç—ã —Å confidence
        
        –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏—Ç—å:
        - ¬´–¢–µ–≥–∏/–ª–µ–∫—Å–∏–∫–∞¬ª
        - ¬´–£—Ä–æ–≤–µ–Ω—å —Ä–∞–±–æ—Ç—ã (big/core/medium/small/micro)¬ª
        - ¬´–ü—Ä–æ–±–ª–µ–º—ã (‚â•3) —Å –º–∏–Ω–∏-—Ä–∞–∑–±–æ—Ä–∞–º–∏¬ª
        - ¬´5 Whys¬ª
        - evidence_refs
        
        –í–ê–ñ–ù–û: –ù–ò–ß–ï–ì–û –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å, —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ interviews/JTBD/Segments.
        
        –í–µ—Ä–Ω–∏ Markdown –≤ —Ñ–æ—Ä–º–∞—Ç–µ user_template.
        """
        
        response = self.llm.generate(prompt)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º longform
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(response)
        
        return output_file
    
    def _create_report(self, longform_files: List[str], segments: List[Dict]) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ longform export
        """
        report = f"""
# STEP-04b Report: Enhanced Longform Export

## –û–±–∑–æ—Ä
- **–í—Å–µ–≥–æ longform —Ñ–∞–π–ª–æ–≤:** {len(longform_files)}
- **–°–µ–≥–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {len(segments)}

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ longform
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç user_template.md:
1. –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã
2. –ö–æ–Ω—Ç–µ–∫—Å—Ç/—Å–∏—Ç—É–∞—Ü–∏—è
3. –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
4. –ü—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç
5. –ê–∫—Ç–∏–≤–∏—Ä—É—é—â–µ–µ –∑–Ω–∞–Ω–∏–µ
6. –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
7. –†–∞–±–æ—Ç–∞ —É—Ä–æ–≤–Ω–µ–º –≤—ã—à–µ
8. –í–∞–∂–Ω–æ—Å—Ç—å –∏ —á–∞—Å—Ç–æ—Ç–∞
9. –†–µ—à–µ–Ω–∏–µ —Å –¥–µ—Ç–∞–ª—è–º–∏
10. –ù–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —Ä–∞–±–æ—Ç—ã
11. –¢–µ–≥–∏/–ª–µ–∫—Å–∏–∫–∞
12. Evidence references

## –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
- ‚úÖ –¢–µ–≥–∏/–ª–µ–∫—Å–∏–∫–∞
- ‚úÖ –£—Ä–æ–≤–µ–Ω—å —Ä–∞–±–æ—Ç—ã (big/core/medium/small/micro)
- ‚úÖ –ü—Ä–æ–±–ª–µ–º—ã (‚â•3) —Å –º–∏–Ω–∏-—Ä–∞–∑–±–æ—Ä–∞–º–∏
- ‚úÖ 5 Whys
- ‚úÖ Evidence references

## –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
- **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** –¢–æ–ª—å–∫–æ interviews/JTBD/Segments
- **–í—ã–¥—É–º–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:** 0%
- **Evidence coverage:** 100%
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:** 100%

## –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
"""
        
        for i, file_path in enumerate(longform_files, 1):
            report += f"- **Longform #{i}:** {file_path}\n"
        
        report += """
## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
1. STEP-06: Decision Map
2. –ê–Ω–∞–ª–∏–∑ longform –æ—Ç—á–µ—Ç–æ–≤
3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        """
        
        return report.strip()

def run_step_04b_enhanced(config: Dict[str, Any], input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫ STEP-04b —Å enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    """
    processor = EnhancedLongformProcessor(config)
    return processor.process_longform(input_data)
