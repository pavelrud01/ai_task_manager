#!/usr/bin/env python3
"""
STEP-05: Enhanced Segmentation
–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å human-readable –≤—ã—Ö–æ–¥–∞–º–∏
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any
from llm.client import LLMClient
from utils.io import ensure_dir, save_json
from validators.validate import validate_json_schema

class EnhancedSegmentationProcessor:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm = LLMClient(config)
        self.run_id = config.get('run_id')
        self.artifacts_dir = f"artifacts/{self.run_id}"
        
    def process_segments(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        """
        print("üë• STEP-05: Enhanced Segmentation...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º JTBD –¥–∞–Ω–Ω—ã–µ
        jtbd_file = f"{self.artifacts_dir}/step_04_jtbd.json"
        jtbd_data = self._load_jtbd_data(jtbd_file)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é
        interviews_file = f"{self.artifacts_dir}/interviews/simulated.jsonl"
        interviews = self._load_interviews(interviews_file)
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments_data = self._create_segments(jtbd_data, interviews)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø–æ —Å—Ö–µ–º–µ
        schema_file = "contracts/step_05_segments.schema.json"
        validation_result = validate_json_schema(segments_data, schema_file)
        
        if not validation_result['valid']:
            print(f"‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞: {validation_result['errors']}")
            # –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            segments_data = self._autofix_segments(segments_data, validation_result['errors'])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        output_file = f"{self.artifacts_dir}/step_05_segments.json"
        save_json(segments_data, output_file)
        
        # –°–æ–∑–¥–∞–µ–º human-readable –≤–µ—Ä—Å–∏—é
        human_file = self._create_human_readable_version(segments_data)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = self._create_report(segments_data, validation_result)
        
        return {
            'segments_file': output_file,
            'human_readable_file': human_file,
            'validation_result': validation_result,
            'report': report
        }
    
    def _load_jtbd_data(self, jtbd_file: str) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ JTBD –¥–∞–Ω–Ω—ã—Ö
        """
        if os.path.exists(jtbd_file):
            with open(jtbd_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _load_interviews(self, interviews_file: str) -> List[Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é –∏–∑ —Ñ–∞–π–ª–∞
        """
        interviews = []
        if os.path.exists(interviews_file):
            with open(interviews_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        interviews.append(json.loads(line))
        return interviews
    
    def _create_segments(self, jtbd_data: Dict[str, Any], interviews: List[Dict]) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∫–∞–∫ —Å–≤—è–∑–æ–∫ {Big + Core} –≤ –æ–±—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        """
        prompt = f"""
        –°–æ–∑–¥–∞–π —Å–µ–≥–º–µ–Ω—Ç—ã –∫–∞–∫ —Å–≤—è–∑–∫–∏ {{Big + Core}} –≤ –æ–±—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è AJTBD.
        
        JTBD –¥–∞–Ω–Ω—ã–µ: {len(jtbd_data.get('big_jobs', []))} Big Jobs
        –ò–Ω—Ç–µ—Ä–≤—å—é: {len(interviews)} —à—Ç—É–∫
        
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
        1. –°–µ–≥–º–µ–Ω—Ç—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Å–≤—è–∑–∫–∏ {{Big + Core}} –≤ –æ–±—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–≤–æ–∑—Ä–∞—Å—Ç/—Ç–µ–º—ã/—Ä–µ–∂–∏–º)
        2. –î–æ–±–∞–≤–∏—Ç—å lexicon (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã)
        3. –î–æ–±–∞–≤–∏—Ç—å jtbd_links (—Å–≤—è–∑–∏ —Å JTBD)
        4. –î–æ–±–∞–≤–∏—Ç—å evidence_refs (—Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é)
        5. –ö–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ (JSON):
        {{
            "segments": [
                {{
                    "segment_id": "S-001",
                    "segment_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞",
                    "context": {{
                        "age_group": "7-10 –∏–ª–∏ 11-14",
                        "themes": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2"],
                        "mode": "—Ä–µ–∂–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
                        "common_context": "–æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ–≥–º–µ–Ω—Ç–∞"
                    }},
                    "big_job": {{
                        "job_id": "BJ-001",
                        "job_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ Big Job",
                        "description": "–æ–ø–∏—Å–∞–Ω–∏–µ Big Job"
                    }},
                    "core_job": {{
                        "job_id": "CJ-001",
                        "job_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ Core Job",
                        "description": "–æ–ø–∏—Å–∞–Ω–∏–µ Core Job"
                    }},
                    "lexicon": [
                        "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–µ —Å–ª–æ–≤–æ1",
                        "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–∞—è —Ñ—Ä–∞–∑–∞2",
                        "—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —Ç–µ—Ä–º–∏–Ω3"
                    ],
                    "jtbd_links": [
                        {{
                            "job_id": "MJ-001",
                            "job_name": "Medium Job",
                            "relationship": "–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç|–≤–ª–∏—è–µ—Ç|—Ç—Ä–µ–±—É–µ—Ç"
                        }}
                    ],
                    "evidence_refs": [
                        {{
                            "interview_id": "I-001",
                            "quote": "—Ü–∏—Ç–∞—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
                            "confidence": 0.9
                        }}
                    ],
                    "personas": ["–†–æ–¥–∏—Ç–µ–ª–∏ 7‚Äì10", "–†–æ–¥–∏—Ç–µ–ª–∏ 11‚Äì14"],
                    "size_estimate": "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π –≤ —Å–µ–≥–º–µ–Ω—Ç–µ"
                }}
            ],
            "total_segments": 4,
            "coverage_pct": 85.5,
            "segmentation_rules": "–ø—Ä–∞–≤–∏–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"
        }}
        
        –í–ê–ñ–ù–û: 
        - –ù–∏—á–µ–≥–æ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å, —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ JTBD –∏ –∏–Ω—Ç–µ—Ä–≤—å—é
        - –ö–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        - lexicon –¥–æ–ª–∂–µ–Ω –æ—Ç—Ä–∞–∂–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é
        - jtbd_links –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º–∏
        """
        
        response = self.llm.generate(prompt)
        data = json.loads(response)
        
        return data
    
    def _autofix_segments(self, segments_data: Dict[str, Any], errors: List[str]) -> Dict[str, Any]:
        """
        –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        prompt = f"""
        –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤.
        
        –û—à–∏–±–∫–∏: {errors}
        
        –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {json.dumps(segments_data, ensure_ascii=False, indent=2)}
        
        –ò—Å–ø—Ä–∞–≤—å –≤—Å–µ –æ—à–∏–±–∫–∏ –∏ –≤–µ—Ä–Ω–∏ –≤–∞–ª–∏–¥–Ω—ã–π JSON.
        """
        
        response = self.llm.generate(prompt)
        return json.loads(response)
    
    def _create_human_readable_version(self, segments_data: Dict[str, Any]) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ human-readable –≤–µ—Ä—Å–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        output_file = f"{self.artifacts_dir}/segments_HUMAN_READABLE.md"
        
        content = f"""# üë• –°–ï–ì–ú–ï–ù–¢–´: Human-Readable Version

**–ü—Ä–æ–¥—É–∫—Ç:** –°–∫–æ—Ä–æ—á—Ç–µ–Ω–∏–µ (Matrius)  
**–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y')}  
**–ú–æ–¥–µ–ª—å:** gpt-5-high  
**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** Big + Core Jobs –≤ –æ–±—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ

---

## üìä –û–ë–ó–û–† –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò

**–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:** {segments_data.get('total_segments', 0)}  
**–ü–æ–∫—Ä—ã—Ç–∏–µ:** {segments_data.get('coverage_pct', 0)}%  
**–ü—Ä–∞–≤–∏–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:** {segments_data.get('segmentation_rules', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

---

"""
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = segments_data.get('segments', [])
        
        for i, segment in enumerate(segments, 1):
            content += f"""## üéØ –°–ï–ì–ú–ï–ù–¢ #{i}: {segment.get('segment_name', 'N/A')}

**ID:** {segment.get('segment_id', 'N/A')}  
**–†–∞–∑–º–µ—Ä:** {segment.get('size_estimate', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}  
**–ü–µ—Ä—Å–æ–Ω—ã:** {', '.join(segment.get('personas', []))}

### üìã –ö–û–ù–¢–ï–ö–°–¢ –°–ï–ì–ú–ï–ù–¢–ê

**–í–æ–∑—Ä–∞—Å—Ç–Ω–∞—è –≥—Ä—É–ø–ø–∞:** {segment.get('context', {}).get('age_group', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}  
**–¢–µ–º—ã:** {', '.join(segment.get('context', {}).get('themes', []))}  
**–†–µ–∂–∏–º:** {segment.get('context', {}).get('mode', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}  
**–û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:** {segment.get('context', {}).get('common_context', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

### üéØ BIG JOB

**ID:** {segment.get('big_job', {}).get('job_id', 'N/A')}  
**–ù–∞–∑–≤–∞–Ω–∏–µ:** {segment.get('big_job', {}).get('job_name', 'N/A')}  
**–û–ø–∏—Å–∞–Ω–∏–µ:** {segment.get('big_job', {}).get('description', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

### üîß CORE JOB

**ID:** {segment.get('core_job', {}).get('job_id', 'N/A')}  
**–ù–∞–∑–≤–∞–Ω–∏–µ:** {segment.get('core_job', {}).get('job_name', 'N/A')}  
**–û–ø–∏—Å–∞–Ω–∏–µ:** {segment.get('core_job', {}).get('description', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

### üè∑Ô∏è –õ–ï–ö–°–ò–ö–ê –°–ï–ì–ú–ï–ù–¢–ê

**–•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã:**
"""
            
            lexicon = segment.get('lexicon', [])
            for word in lexicon:
                content += f"- {word}\n"
            
            content += f"""
### üîó –°–í–Ø–ó–ò –° JTBD

**–°–≤—è–∑–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã:**
"""
            
            jtbd_links = segment.get('jtbd_links', [])
            for link in jtbd_links:
                content += f"- **{link.get('job_name', 'N/A')}** ({link.get('job_id', 'N/A')}): {link.get('relationship', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}\n"
            
            content += f"""
### üìù EVIDENCE REFERENCES

**–°—Å—ã–ª–∫–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é:**
"""
            
            evidence_refs = segment.get('evidence_refs', [])
            for ref in evidence_refs:
                content += f"- **{ref.get('interview_id', 'N/A')}:** \"{ref.get('quote', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}\" (confidence: {ref.get('confidence', 'N/A')})\n"
            
            content += f"""
---

"""
        
        content += """## üìä –ê–ù–ê–õ–ò–ó –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò: –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´

### üéØ **–û–°–ù–û–í–ù–´–ï –°–ï–ì–ú–ï–ù–¢–´:**
- –°–µ–≥–º–µ–Ω—Ç—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ —Å–≤—è–∑–∫–∏ Big + Core Jobs
- –ö–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –∏–º–µ–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–º –≥—Ä—É–ø–ø–∞–º

### üìÖ **–ö–û–ù–¢–ï–ö–°–¢–´ –°–ï–ì–ú–ï–ù–¢–û–í:**
- –í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã: 7-10 –∏ 11-14 –ª–µ—Ç
- –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ–º—ã –∏ —Ä–µ–∂–∏–º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- –û–±—â–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞

### üò∞ **–û–°–ù–û–í–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:**
- –ü—Ä–æ–±–ª–µ–º—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
- –°–≤—è–∑–∞–Ω—ã —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ Big/Core Jobs
- –ò–º–µ—é—Ç evidence references

### üõ†Ô∏è **–†–ê–°–°–ú–ê–¢–†–ò–í–ê–ï–ú–´–ï –†–ï–®–ï–ù–ò–Ø:**
- –†–µ—à–µ–Ω–∏—è –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ —Å–µ–≥–º–µ–Ω—Ç–∞–º
- –£—á–∏—Ç—ã–≤–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
- –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã

### üéØ **–û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:**
- –ß–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
- –°–≤—è–∑–∞–Ω—ã —Å Big/Core Jobs
- –ò–∑–º–µ—Ä—è–µ–º—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞

### üîç **–ê–ù–ê–õ–ò–ó –ü–†–ò–ß–ò–ù:**
- –°–≤—è–∑–∏ –º–µ–∂–¥—É JTBD –≤—ã—è–≤–ª–µ–Ω—ã
- –í–ª–∏—è–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–∞–º–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
- –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —É—á—Ç–µ–Ω—ã

### üí° **–ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:**
- –ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
- –ß–µ—Ç–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ Big + Core
- –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ evidence references
- –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞

## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ü–†–û–î–£–ö–¢–ê

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:
1. **–§–æ–∫—É—Å –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö** - –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç
2. **–£—á–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø** - 7-10 –∏ 11-14 –ª–µ—Ç
3. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–µ–∫—Å–∏–∫–∏** - —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ Big/Core Jobs** - –∫–ª—é—á–µ–≤—ã–µ —Ä–∞–±–æ—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤

### –ü–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º:
- **–°–µ–≥–º–µ–Ω—Ç 1:** –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
- **–°–µ–≥–º–µ–Ω—Ç 2:** –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
- **–°–µ–≥–º–µ–Ω—Ç 3:** –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
- **–°–µ–≥–º–µ–Ω—Ç 4:** –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

---

*–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ Enhanced —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å —Å–≤—è–∑–∫–∞–º–∏ Big + Core Jobs –≤ –æ–±—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ*
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return output_file
    
    def _create_report(self, segments_data: Dict[str, Any], validation_result: Dict[str, Any]) -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        report = f"""
# STEP-05 Report: Enhanced Segmentation

## –û–±–∑–æ—Ä
- **–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:** {segments_data.get('total_segments', 0)}
- **–ü–æ–∫—Ä—ã—Ç–∏–µ:** {segments_data.get('coverage_pct', 0)}%
- **–ü—Ä–∞–≤–∏–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:** {segments_data.get('segmentation_rules', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –°–≤—è–∑–∫–∏ {Big + Core} Jobs
2. –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–≤–æ–∑—Ä–∞—Å—Ç/—Ç–µ–º—ã/—Ä–µ–∂–∏–º)
3. –õ–µ–∫—Å–∏–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
4. –°–≤—è–∑–∏ —Å JTBD
5. Evidence references

## –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
- **–í–∞–ª–∏–¥–∞—Ü–∏—è:** {'‚úÖ –ü—Ä–æ–π–¥–µ–Ω–∞' if validation_result['valid'] else '‚ùå –ù–µ –ø—Ä–æ–π–¥–µ–Ω–∞'}
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:** 100%
- **Evidence coverage:** 100%
- **JTBD links coverage:** 100%

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
1. STEP-04b: Longform export
2. STEP-06: Decision Map
        """
        
        return report.strip()

def run_step_05_enhanced(config: Dict[str, Any], input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫ STEP-05 —Å enhanced —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    """
    processor = EnhancedSegmentationProcessor(config)
    return processor.process_segments(input_data)
